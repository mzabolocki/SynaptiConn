{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Single-unit spike data demo\n\nAn example analysis applied to single-unit spike-sorted spiketrain data, demonstrating\nbest practices for monosynaptic pair analysis with the synapticonn package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monosynaptic connection analysis demo\n\nThis example demonstrates how to perform a monosynaptic connection analysis.\n\nHere, we use an existing published dataset of single-unit spiketrains\nrecorded from mice.\n\nThe dataset is available via the link: 10.1016/j.celrep.2023.113475\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Import necessary modules\nimport os\nimport pathlib\nimport scipy.io\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport synapticonn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load spike times data\n\nFirst, load your spike times data. Here, we load the spike times data from a\n.mat file. The spike times data should be a list of spike times for each\nneuron in the dataset. The spike times should be in seconds or milliseconds.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_fpath = pathlib.Path('examples', 'analyses', 'data', 'all_unit.mat')\n\n# open mat file\ndata = scipy.io.loadmat(data_fpath)\n# get all spiketrain units and convert to milliseconds\nall_units = {i: data['unit_t'][0][i].T[0] * 1000 for i in range(len(data['unit_t'][0]))}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize the object\n\nInitialize the SynaptiConn object.\n\nBefore doing so, it is important to ensure your spike times data is in the\ncorrect format. The spike times data should be a dictionary where the keys\nare the unit IDs and the values are the spike times for each unit.\n\nThe spike times should be in seconds or milliseconds. Please change the time_unit\naccordingly to relfect this.The sampling rate should be specified in Hz, and is\nessential for the analysis. The recording length should also be specified in seconds or milliseconds.\n\nCurrently, the method 'cross-correlation' is supported for monosynaptic pair analysis. In this method,\nthe cross-correlation between the spike trains is computed. The bin size for the cross-correlation\nshould be specified in the time unit used for the spike times data. In future versions of the package,\nmore methods will be supported.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snc = synapticonn.SynaptiConn(all_units,\n                              method='cross-correlation',\n                              bin_size_t=1,\n                              time_unit='ms',\n                              max_lag_t=200,\n                              srate=20_000,\n                              recording_length_t=1000*1000,\n                              spike_id_type=int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we have initialized the SynaptiConn object. We can now proceed to the\nanalysis. However, before proceeding, it is important to check the loaded\nspike times data. The spike times data should be in the correct format.\n\nto do so, SynaptiConn provides a method 'report_spike_units' to check the spike times data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spk_unit_report = snc.report_spike_units()\nprint(spk_unit_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spike-unit quality metrics\n\nBefore continuining, it is important to cross-check the quality of the spike sorted neurons. \nMetrics related to the spike quality can be found below. Notably, the autocorrelograms\nfor each unit should also be cross-referenced prior to continuing.\nLow contamination (or no contamination) in the refractory periods are important\nfor correct assesments of spike-units and their monosynaptic connections.\n\nFor further quality metrics, and explanations, please refer to the following: https://github.com/SpikeInterface/spikeinterface/blob/main/src/spikeinterface/qualitymetrics/misc_metrics.py#L1183.\n\n**NOTE** here, more simple and core metric assessments are performed.\nIn the future, these will be extended.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# note :: isi min should be based on the\n# miniimum possible refractory period (e.g. spikes removed would constitute this)\n# isi threshold should be based on the refractory period of the neuron\n\nparams = {'isi_threshold_ms': 1.5,\n          'min_isi_ms': 0,\n          'presence_ratio_bin_duration_sec': 60,\n          'presence_ratio_mean_fr_ratio_thresh': 0.0}\n\nqc = snc.spike_unit_quality(**params)\nqc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter the spike times for 'good units' based on the quality control metrics. These will then be used for all further processing. The spike times will be updated accordingly. A log of the excluded units can be found and kept.\n\n###############################################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "query = 'firing_rate_hz > 0.5'\ngood_units = snc.filter_spike_units(qc, query, log=True)\ngood_units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Auto-correlograms\n\nBefore proceeding with the monosynaptic pair analysis, visualize\nthe auto-correlograms for each unit. This is important to check for\ncontamination in the refractory period.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snc.plot_autocorrelogram(spike_units=[1, 8], color='blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the bin parameters after initialization, and re-plot.\n\nThis can be used to change the binning on the plots, and max time lags.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snc.set_bin_settings(bin_size_t=0.5, max_lag_t=10, time_unit='ms')\nsnc.plot_autocorrelogram(spike_units=[0, 1, 8, 10], color='blue', figsize=(20, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-correlograms\n\nVisualize cross-correlograms between pairs.\n\nBin size and time lag can be changed by re-setting the bins.\nHowever, for improved visualizations and reporting a smaller bin size and time lag is recommended.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spk_units = snc.spike_times.keys()\n\n# make a list of all possible pairs\npairs = []\nfor i, unit1 in enumerate(spk_units):\n    for j, unit2 in enumerate(spk_units):\n        if i < j:\n            pairs.append((unit1, unit2))\n\n# subselect for select pairs\nspike_pairs = pairs[4:8]\n\n# plot cross-correlograms\nsnc.plot_crosscorrelogram(spike_pairs=spike_pairs, figsize=(20, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-correlogram data\n\nNext, try returning the correlogram data.\n\nEach key in 'cross_correlations' is indexed by the unit pairs.\nThe corresponding numbers refer to the spike counts, per bin.\n\nEach key in 'bins' is also indexed by the unit pairs.\nThe corresponding numbers refer to the bins edges.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correlogram_data = snc.return_crosscorrelogram_data(spike_pairs=spike_pairs)\ncorrelogram_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the bin settings using for correlogram generations.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snc.report_correlogram_settings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute monosynaptic connections\n\nCompute excitatory and inhibitory monosynaptic connections between spike trains. \n\nThis analysis was based on the following reference by Najafi.\nA link to the paper can be found here: https://doi.org/10.1016/j.neuron.2019.09.045.\n\nThis protocol was based on data and experimental analyses provided in the paper, found here: 10.1016/j.celrep.2023.113475.\n\n**Computational strength calculations notes**\n\n- `First, compute synaptic strength for a set of neuron IDs. If a given unit consistently fires after a second unit, indicated by a peak in the CCG, there is high chance that these cells are functionally linked either directly through an excitatory synaptic connection or indirectly through a third neuron providing a common input.`\n- `To compute synaptic strength, the firing of a single unit in a pair was jittered across a number of iterations (num_iterations) within a time range (jitter_range_ms).`\n- `These were used to calculate a confidence interval (CI) between 1% and 99%. If the real CCG peak passed the 99% CI, the corresponding functional connection would be considered significant and not random.`\n- `A z-score was then performed using the following equation: Z = x_real - mean_jitter / std_jitter`\n\n\nNote that the output contains the following keys:\n\n- `ccg bins``\n- `ccg counts (from original spike trains)`\n- `ccg counts (post jitter)`\n- `synaptic strength`\n- `high confidence interval (99%), calculated on jittered ccg`\n- `low confidence interval (1%), calculation on jittered ccg`\n- `ccg counts (within jitter range window)`\n- `low confidence interal (1%), within jitter range window`\n- `high confidence interal (99%), within jitter range window`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "synaptic_strength_data = snc.synaptic_strength(spike_pairs=spike_pairs,\n                                               num_iterations=1000,\n                                               jitter_range_t=10)\n\n# isolate single neuron pair\npair = (0, 6)\nsynaptic_strength_data[pair]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the synaptic strength data for a select pair.\n\nThis can be done automatically by plotting the original ccg, and the z-scored value.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snc.plot_synaptic_strength(spike_pair=(0, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Next, check the connection type.**\n\nHere, we can perform a putative detection using the z-score (synaptic strength) output.\n\nThresholds should be set as > 5 for excitatory-connections, or inhibitory connections\nas < -5 based on the reference protocol.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exc_connection_types = snc.monosynaptic_connection_types(synaptic_strength_threshold=5)\nexc_df = pd.DataFrame(exc_connection_types).T\nexc_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output a features dataframe containing selected spike pair connections and associated ccg features.\n\nThese can be used to provide simple information on the quality of the CCG, and associated connection types.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "synaptic_features = snc.monosynaptic_connection_features()\nsynaptic_features_df = pd.DataFrame(synaptic_features).T\nsynaptic_features_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output dataframes can be merged for simplicity and further analyses.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "merged_df = exc_df.join(synaptic_features_df)\nmerged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit & report\n\nAlternatively, there is a simpler method to compute monosynaptic connections. Simply, monosynaptic connections can be inferred in one line. This combines the period methods.\n\nFor feature extractions, this can be performed separately and combined.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "connections = snc.fit(spike_pairs, synaptic_strength_threshold=5, num_iterations=1000)\nconnections = pd.DataFrame(connections).T\nconnections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summarize the data outputs using report. This is a convience method that calls a series of methods:\n\n- `fit()`\n- `print_results()`\n\nEach of these methods can be used individually.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snc.report(spike_pairs, synaptic_strength_threshold=5, num_iterations=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Monosnyaptic connection quality control\n\nNext, check the results. It is important to ensure the connections are truely monosynaptic, and not polysynaptic or simply a byproduct of poorly isolated spike-units.\n\nTo do so, there are several in-built modules to check the quality of the outputs. These are based on the type of connections and time-lag threshold estimates.\n\n**Acceptance criteria**\n\n- `Excitatory connections between cells located near each other should occur within 2 ms.`\n- `The monosynaptic peak should also be shaped as a double expontential function with a fast rise and a slower decay. Inhibitory connections have a slower decay, and should be factored into your QC metrics.`\n\n**Rejection criteria**\n\n- `If the CCG shows a maintained refractory period, it suggests that the spikes should have been merged in the spike-sorting process. Hence, if a monosynaptic peak is seen, then it is likely because it is the same neuron which has not been correctly merged.`\n- `If the CCG peak coincides with the ACG peak (usually slower than 2 ms), the unit likely should have been merged in the spike sorting process, of the cell-pair is probably contaminated with a 3rd pair.`\n- `A broad centrally aligned CCG peak indicates common drive, and therefore should be rejected. This is often seen when comparing two cells located at different shanks (> hundreds of um apart). This can be difficult to differentiate.`\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# simply, a way to filter the connections based on the peak time of the ccg\n# is to convert the connection data to a dataframe and then query it using pandas\n\nquery = 'ccg_peak_time_ms > 1 & ccg_peak_time_ms < 4'\nconnection_df_filtered = connections.query(query)\n\nprint(f'Number of exc connections: {len(connections)}')\nprint(f'Number of exc connections after filtering: {len(connection_df_filtered)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Beyond a simply df query, the main object can be filtered for units to be rejected. Here, a log can be \nprovided.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "snc.filter_connections(connections, query, log=True, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion\n\nFor more information on the methods and classes used in this example, please refer to the documentation.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}